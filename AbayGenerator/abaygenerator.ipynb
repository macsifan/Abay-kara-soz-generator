{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "colab": {},
    "colab_type": "code",
    "id": "Jwt6UdnNqVPm"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import numpy as np\n",
    "import codecs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "6kXb2ifEqVPq",
    "outputId": "cd6bd6aa-df3d-40b0-a678-2e63b3a9fe9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 116959 total characters and 83 unique characters in your data.\n"
     ]
    }
   ],
   "source": [
    "fileObj = codecs.open( \"data.txt\", \"r\", \"utf_8_sig\" )\n",
    "data= fileObj.read()\n",
    "data=data.replace(\"\\n\",'')\n",
    "data=data.replace(\"\\r\",'')\n",
    "fileObj.close()\n",
    "chars = list(set(data))\n",
    "data_size, vocab_size = len(data), len(chars)\n",
    "print('There are %d total characters and %d unique characters in your data.' % (data_size, vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Бұл жасқа келгенше жақсы өткіздік пе, жаман өткіздік пе, әйтеуір бірталай өмірімізді өткіздік: алыстық, жұлыстық, айтыстық, тартыстық - әурешілікті көре-көре келдік. Енді жер ортасы жасқа келдік: қажыдық, жалықтық; қылып жүрген ісіміздің баянсызын, байлаусызын көрдік, бәрі қоршылық екенін білдік. Ал, енді қалған өмірімізді қайтіп, не қылып өткіземіз? Соны таба алмай өзім де қайранмын.Ел бағу? Жоқ, елге бағым жоқ. Бағусыз дертке ұшырайын деген кісі бақпаса, не албыртқан, көңілі басылмаған жастар бағамын демесе, бізді құдай сақтасын!Мал бағу? Жоқ, баға алмаймын. Балалар өздеріне керегінше өздері бағар. Енді қартайғанда қызығын өзің түгел көре алмайтұғын, ұры, залым, тілемсектердің азығын бағып беремін деп, қалған аз ғана өмірімді қор қылар жайым жоқ.Ғылым бағу? Жоқ, ғылым бағарға да ғылым сөзін сөйлесер адам жоқ. Білгеніңді кімге үйретерсің, білмегеніңді кімнен сұрарсың? Елсіз-күнсізде кездемені жайып салып, қолына кезін алып отырғанның не пайдасы бар? Мұңдасып шер тарқатысар кісі болмаған соң, ғылым өзі - бір тез қартайтатұғын күйік.Софылық қылып, дін бағу? Жоқ, ол да болмайды, оған да тыныштық керек. Не көңілде, не көрген күніңде бір тыныштық жоқ, осы елге, осы жерде не қылған софылық?Балаларды бағу? Жоқ, баға алмаймын. Бағар едім, қалайша бағудың мәнісін де білмеймін, не болсын деп бағам, қай елге қосайын, қай харекетке қосайын? Балаларымның өзіне ілгері өмірінің, білімінің пайдасын тыныштықпенен керерлік орын тапқаным жоқ, қайда бар, не қыл дерімді біле алмай отырмын, не бол деп бағам? Оны да ермек қыла алмадым.Ақыры ойладым: осы ойыма келген нәрселерді қағазға жаза берейін, ақ қағаз бен қара сияны ермек қылайын, кімде-кім ішінен керекті сөз тапса, жазып алсын, я оқысын, керегі жоқ десе, өз сөзім өзімдікі дедім де, ақыры осыған байладым, енді мұнан басқа ешбір жұмысым жоқ.Мен бала күнімде естуші едім, біздің қазақ сартты көрсе, күлуші еді «енеңді ұрайын, кең қолтық, шүлдіреген тәжік, Арқадан үй төбесіне саламын деп, қамыс артқан, бұтадан қорыққан, көз көргенде «әк'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "KrKvu85XqVPv",
    "outputId": "509c2576-685f-4782-e09d-8ee77a18cde5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: ' ', 1: '!', 2: '*', 3: ',', 4: '-', 5: '.', 6: ':', 7: ';', 8: '?', 9: '«', 10: '»', 11: 'І', 12: 'А', 13: 'Б', 14: 'Г', 15: 'Д', 16: 'Е', 17: 'Ж', 18: 'З', 19: 'И', 20: 'К', 21: 'Л', 22: 'М', 23: 'Н', 24: 'О', 25: 'П', 26: 'Р', 27: 'С', 28: 'Т', 29: 'У', 30: 'Ф', 31: 'Х', 32: 'Ш', 33: 'Ы', 34: 'Я', 35: 'а', 36: 'б', 37: 'в', 38: 'г', 39: 'д', 40: 'е', 41: 'ж', 42: 'з', 43: 'и', 44: 'й', 45: 'к', 46: 'л', 47: 'м', 48: 'н', 49: 'о', 50: 'п', 51: 'р', 52: 'с', 53: 'т', 54: 'у', 55: 'ф', 56: 'х', 57: 'ц', 58: 'ч', 59: 'ш', 60: 'ы', 61: 'ь', 62: 'э', 63: 'ю', 64: 'я', 65: 'і', 66: 'Ғ', 67: 'ғ', 68: 'Қ', 69: 'қ', 70: 'ң', 71: 'Ү', 72: 'ү', 73: 'Ұ', 74: 'ұ', 75: 'Һ', 76: 'һ', 77: 'Ә', 78: 'ә', 79: 'Ө', 80: 'ө', 81: '–', 82: '—'}\n"
     ]
    }
   ],
   "source": [
    "# unique characters\n",
    "char_to_ix = { ch:i for i,ch in (enumerate(sorted(chars))) }\n",
    "ix_to_char = { i:ch for i,ch in enumerate(sorted(chars)) }\n",
    "print(ix_to_char)\n",
    "encoded = np.array([char_to_ix[ch] for ch in data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "KvwccM9W-qkX",
    "outputId": "89821aea-0161-45fd-9425-6a6dc559492e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on GPU!\n"
     ]
    }
   ],
   "source": [
    "train_on_gpu = torch.cuda.is_available()\n",
    "if(train_on_gpu):\n",
    "    print('Training on GPU!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NOyxmWyDqVPz"
   },
   "outputs": [],
   "source": [
    "def one_hot(arr, n_labels):\n",
    "    one_hot = np.zeros((np.multiply(*arr.shape), n_labels), dtype=np.float32)\n",
    "    one_hot[np.arange(one_hot.shape[0]), arr.flatten()] = 1.\n",
    "    one_hot = one_hot.reshape((*arr.shape, n_labels))\n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dr8M42lc7fzU"
   },
   "outputs": [],
   "source": [
    "def get_batches(arr, batch_size, seq_length):\n",
    "    batch_size_total = batch_size * seq_length\n",
    "    n_batches = len(arr)//batch_size_total\n",
    "    arr = arr[:n_batches * batch_size_total]\n",
    "    arr = arr.reshape((batch_size, -1))\n",
    "    for n in range(0, arr.shape[1], seq_length):\n",
    "        x = arr[:, n:n+seq_length]\n",
    "        y = np.zeros_like(x)\n",
    "        try:\n",
    "            y[:, :-1], y[:, -1] = x[:, 1:], arr[:, n+seq_length]\n",
    "        except IndexError:\n",
    "            y[:, :-1], y[:, -1] = x[:, 1:], arr[:, 0]\n",
    "        yield x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yYwSXHFgqVP1"
   },
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__ (self, chars, n_hidden=256, n_layers=2, drop_prob=0.5, lr=0.001):\n",
    "        super().__init__()\n",
    "        self.drop_prob = drop_prob\n",
    "        self.n_layers = n_layers\n",
    "        self.n_hidden = n_hidden\n",
    "        self.lr = lr\n",
    "        self.chars = chars\n",
    "        self.char_to_ix = { ch:i for i,ch in enumerate(sorted(self.chars)) }\n",
    "        self.ix_to_char = { i:ch for i,ch in enumerate(sorted(self.chars)) }\n",
    "        #set lstm\n",
    "        self.lstm = nn.LSTM(len(self.chars),n_hidden,n_layers,dropout = drop_prob, batch_first = True)\n",
    "        self.dropout = nn.Dropout(drop_prob)\n",
    "        self.fc = nn.Linear(n_hidden, len(self.chars))\n",
    "    def forward(self, x, hidden):\n",
    "        rel, hidden = self.lstm(x, hidden)\n",
    "        out = self.dropout(rel)\n",
    "        out = out.contiguous().view(-1, self.n_hidden)\n",
    "        out = self.fc(out)\n",
    "        return out, hidden\n",
    "    def init_hidden(self, batch_size):\n",
    "        weight = next(self.parameters()).data\n",
    "        hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda(),\n",
    "                  weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda())\n",
    "        \n",
    "        return hidden\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AeNAPFA9w9rw"
   },
   "outputs": [],
   "source": [
    "def train(rnn, data, epochs = 10, lr = 0.001, batch_size = 10 ,seq_length = 50, clip=5, val_frac=0.1, print_every=10):\n",
    "    rnn.train()\n",
    "    optimization = torch.optim.Adam(rnn.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    data, val_data = data[:int(len(data)*(1-val_frac))], data[int(len(data)*(1-val_frac)):]\n",
    "    if(train_on_gpu):\n",
    "        rnn.cuda()\n",
    "    counter = 0\n",
    "    n_chars = len(rnn.chars)\n",
    "  \n",
    "    for e in range(epochs):\n",
    "        n_h = rnn.init_hidden(batch_size)\n",
    "    \n",
    "        for x,y in get_batches(data, batch_size, seq_length):\n",
    "            counter = counter + 1\n",
    "            x = one_hot(x, n_chars)\n",
    "            inputs, targets = torch.from_numpy(x), torch.from_numpy(y)\n",
    "            if(train_on_gpu):\n",
    "                inputs, targets = inputs.cuda(), targets.cuda()\n",
    "            n_h = tuple([every.data for every in n_h])\n",
    "            rnn.zero_grad()\n",
    "            out, n_h = rnn(inputs, n_h)\n",
    "            loss = criterion(out, targets.view(batch_size*seq_length).long())\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(rnn.parameters(), clip)\n",
    "            optimization.step()\n",
    "            if counter % print_every == 0:\n",
    "                val_h = rnn.init_hidden(batch_size)\n",
    "                val_losses = []\n",
    "                rnn.eval()\n",
    "                for x, y in get_batches(val_data, batch_size, seq_length):\n",
    "                    x = one_hot(x, n_chars)\n",
    "                    x, y = torch.from_numpy(x), torch.from_numpy(y)\n",
    "                    val_h = tuple([every.data for every in val_h])\n",
    "                    \n",
    "                    inputs, targets = x, y\n",
    "                    if(train_on_gpu):\n",
    "                        inputs, targets = inputs.cuda(), targets.cuda()\n",
    "                    out, val_h = rnn(inputs, val_h)\n",
    "                    val_loss = criterion(out, targets.view(batch_size*seq_length).long())\n",
    "                \n",
    "                    val_losses.append(val_loss.item())\n",
    "                \n",
    "                rnn.train()\n",
    "                \n",
    "                print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
    "                      \"Step: {}...\".format(counter),\n",
    "                      \"Loss: {:.4f}...\".format(loss.item()))\n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "9G8SphO_5TBE",
    "outputId": "17c8b184-b9bc-418a-ee1d-a74103b80410"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN(\n",
      "  (lstm): LSTM(83, 512, num_layers=2, batch_first=True, dropout=0.5)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (fc): Linear(in_features=512, out_features=83, bias=True)\n",
      ")\n",
      "Epoch: 7/250... Step: 50... Loss: 3.2710...\n",
      "Epoch: 13/250... Step: 100... Loss: 3.1295...\n",
      "Epoch: 19/250... Step: 150... Loss: 2.4925...\n",
      "Epoch: 25/250... Step: 200... Loss: 2.3396...\n",
      "Epoch: 32/250... Step: 250... Loss: 2.1780...\n",
      "Epoch: 38/250... Step: 300... Loss: 2.0822...\n",
      "Epoch: 44/250... Step: 350... Loss: 2.0203...\n",
      "Epoch: 50/250... Step: 400... Loss: 1.9764...\n",
      "Epoch: 57/250... Step: 450... Loss: 1.8786...\n",
      "Epoch: 63/250... Step: 500... Loss: 1.7927...\n",
      "Epoch: 69/250... Step: 550... Loss: 1.7626...\n",
      "Epoch: 75/250... Step: 600... Loss: 1.7381...\n",
      "Epoch: 82/250... Step: 650... Loss: 1.6441...\n",
      "Epoch: 88/250... Step: 700... Loss: 1.5676...\n",
      "Epoch: 94/250... Step: 750... Loss: 1.5453...\n",
      "Epoch: 100/250... Step: 800... Loss: 1.4976...\n",
      "Epoch: 107/250... Step: 850... Loss: 1.4053...\n",
      "Epoch: 113/250... Step: 900... Loss: 1.3360...\n",
      "Epoch: 119/250... Step: 950... Loss: 1.2704...\n",
      "Epoch: 125/250... Step: 1000... Loss: 1.2340...\n",
      "Epoch: 132/250... Step: 1050... Loss: 1.1182...\n",
      "Epoch: 138/250... Step: 1100... Loss: 1.0453...\n",
      "Epoch: 144/250... Step: 1150... Loss: 0.9948...\n",
      "Epoch: 150/250... Step: 1200... Loss: 0.9797...\n",
      "Epoch: 157/250... Step: 1250... Loss: 0.8593...\n",
      "Epoch: 163/250... Step: 1300... Loss: 0.8359...\n",
      "Epoch: 169/250... Step: 1350... Loss: 0.7492...\n",
      "Epoch: 175/250... Step: 1400... Loss: 0.6947...\n",
      "Epoch: 182/250... Step: 1450... Loss: 0.6419...\n",
      "Epoch: 188/250... Step: 1500... Loss: 0.6220...\n",
      "Epoch: 194/250... Step: 1550... Loss: 0.5681...\n",
      "Epoch: 200/250... Step: 1600... Loss: 0.5330...\n",
      "Epoch: 207/250... Step: 1650... Loss: 0.4934...\n",
      "Epoch: 213/250... Step: 1700... Loss: 0.4543...\n",
      "Epoch: 219/250... Step: 1750... Loss: 0.4249...\n",
      "Epoch: 225/250... Step: 1800... Loss: 0.4097...\n",
      "Epoch: 232/250... Step: 1850... Loss: 0.3622...\n",
      "Epoch: 238/250... Step: 1900... Loss: 0.3513...\n",
      "Epoch: 244/250... Step: 1950... Loss: 0.3214...\n",
      "Epoch: 250/250... Step: 2000... Loss: 0.3012...\n"
     ]
    }
   ],
   "source": [
    "n_hidden=512\n",
    "n_layers=2\n",
    "\n",
    "rnn = RNN(chars, n_hidden, n_layers)\n",
    "print(rnn)\n",
    "batch_size = 128\n",
    "seq_length = 100\n",
    "n_epochs = 250\n",
    "train(rnn, encoded, epochs=n_epochs,lr=0.001, batch_size=batch_size, seq_length=seq_length, print_every=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oJ05iemSAoBX"
   },
   "outputs": [],
   "source": [
    "def predict(rnn, char, n_h=None, top_k=None):\n",
    "       \n",
    "        x = np.array([[rnn.char_to_ix[char]]])\n",
    "        x = one_hot(x, len(rnn.chars))\n",
    "        inputs = torch.from_numpy(x)\n",
    "        \n",
    "        if(train_on_gpu):\n",
    "            inputs = inputs.cuda()\n",
    "   \n",
    "        n_h = tuple([every.data for every in n_h])\n",
    "       \n",
    "        out, n_h = rnn(inputs, n_h)\n",
    "\n",
    "       \n",
    "        p = F.softmax(out, dim=1).data\n",
    "        if(train_on_gpu):\n",
    "            p = p.cpu() \n",
    "        \n",
    "    \n",
    "        if top_k is None:\n",
    "            top_ch = np.arange(len(rnn.chars))\n",
    "        else:\n",
    "            p, top_ch = p.topk(top_k)\n",
    "            top_ch = top_ch.numpy().squeeze()\n",
    "        \n",
    "        \n",
    "        p = p.numpy().squeeze()\n",
    "        char = np.random.choice(top_ch, p=p/p.sum())\n",
    "        \n",
    "        \n",
    "        return rnn.ix_to_char[char], n_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 578
    },
    "colab_type": "code",
    "id": "Dvt1zsU9BU0D",
    "outputId": "9b3aad24-6f50-467f-f4b0-fe8e74a65536"
   },
   "outputs": [],
   "source": [
    "def sample(rnn, size, prime='The', top_k=None):\n",
    "        \n",
    "    if(train_on_gpu):\n",
    "        rnn.cuda()\n",
    "    else:\n",
    "        rnn.cpu()\n",
    "    \n",
    "    rnn.eval() \n",
    "    \n",
    "   \n",
    "    chars = [ch for ch in prime]\n",
    "    n_h = rnn.init_hidden(1)\n",
    "    for ch in prime:\n",
    "        char, n_h = predict(rnn, ch, n_h, top_k=top_k)\n",
    "\n",
    "    chars.append(char)\n",
    "    \n",
    "    \n",
    "    for ii in range(size):\n",
    "        char, n_h = predict(rnn, chars[-1], n_h, top_k=top_k)\n",
    "        chars.append(char)\n",
    "\n",
    "    return ''.join(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ақылсаң берік елгенсе, осындай жіберген жоқ дой, оным жүнге  біріп ұғыным. Және манданың өзінде біргені бар болса, ауылы жаратпан, өнгерінің көңілінде ақыл қылып, өзі де уайымызға жақатына саламақ еді, өні ді үсін шайға барынды жалып, сізінің бағыпы, жөті мастынеп, артылары бар болса, айтылған себеп балалық шалыққандары алда, жаратқан жоқ деп анамендей біреуіне салып болады. Бұл ғадаләт рафы болмасыңдар. Олай болғанда қиыр жұратып жүрмес пе? Олар болсанда қайметемен түрлі - сұларға тұр болсын. Оның жәбебі нарлифа бұр ғадаләттен шығады. Оның үшін мәхкірленене себеп, наһәрларыманан сауға алады, хасуа да харат болмаса, не қылған мендеге ештіренен айтқан болса, бұрат болмақсызын бәр бар, зызын өзімен қарғана кісі бермей болады. Оның жарғы барып, жауыны танып, адам балысына пейделіктен көргенде, біргеніңде болып қалып, мақтайды қартайлық қайырлықып, жұрып болар, мақтаншақ мен ойлапайды.Дүнлеге қуаныш бар қолған кісінің, қосындан өткізіп, мешілім-жерге дүгиетің, жоқсы, ана екеуін жымдылық, сұр\n"
     ]
    }
   ],
   "source": [
    "print(sample(rnn, 1000, prime='А', top_k=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Бісен деп асартар емес, соғим барлықты камдым қайдап қара жасқа қорақтат да жардасын деп қайтып, кеңерін болады. Жән бір өздері жарым адамдығынан жақты бер! Ол адамның өнірімеғі еңді болсын, әрдісінің өзінің адамдығынаны табын болады. Әуелі — ай, нәрсенің ретінің сөзге үйренеп екен. Қазақ денберек хайықта жұқ болса, өнер құдай тағала бір қалмаған құдійері. Мантаның шарық қылған құдай тағала айғып кетеді.Екінші - өзіңдің өскізін сынатұғын аламын да болған. Бұлар тынымандың ішкі сыларып саласып келсе, аланды баса жазалардан орлық бар. Бұлар да аудан саңпасың көр сүреп ештіңге көрген мұманды жоқ болады. Бірау - ол дау өзер ейліп, еск сен де болып түрре мақтық, көмінбесін кіміз жақсы адамның көнісіне  жоқ. Кей бай, өзі аныратұғаны екен. Созда қылмаса, екеуді ішім келеді: «ақыр құдайғы жазарып, жауысына ұқсырып, ақыл үйрену еліп, қал жәрек болып кетсе, жамын жаққа тарамасан еке де, онайында бір күні бағып ке мақтан дап, кеңбей қалмын деп қалап жерсе, керістік жеп, асып алтанға да қылы болайым\n"
     ]
    }
   ],
   "source": [
    "print(sample(rnn, 1000, prime='Б', top_k=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Енді ой сазлақтар - хакімерсе, едес болмаса, бұзақ балақын баласынамын. Егер беріктерінің жақсылық биретіп жерге де қарамаатып жаратып оллады деп аламыз бе, бірдің қазақ білінді білмейді, өзін- жар келіп тапса, жана қайшылыкқан соң амақ шайда болады. Монда аябып аутықтан бағқта кіргенде, бірін айтып бұр тағы болмас үй, ғылым біреуге жарамылға ұртық, иманды толық кісі болапыз. Әкбәр ман болады далғарлық, көңілге сизатының ішінде не қаламын деп, жұртыс болады. Бірлік қартық алмайтыбы бара жақылыптқа тұрмастың екені деге мер көтеді. Тагаршаны да жарсып, жарлысын, қуат жүріп, бұрық қызақ, жақ - құзыққа алмал жасып жүрек. Жарып малазының ақылығы, күнін үйренбектің тілін жес көріп, ол сөзіп жарарсыздар бірлік қылады. Дүниеде қушақ болып, тамыным жоқ, седей ме? Өздере терсе керек, сондайың біліп, үйреніп кетесіз. Бұлардың айты жере де жеріп, сол мен бірдің болмаса да болмаса, біз мәле батырмағын жауған құра, жүрік қылап таралады. Жоқдағы таланып адам да саласады. Осы көнің әмелші түрлі нәрселін\n"
     ]
    }
   ],
   "source": [
    "print(sample(rnn, 1000, prime='Е', top_k=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Мын, яғни айтқаныңнан бары жоқ. Бірақ ойнан қалып кісіпіп жасып кетпейді екен, сатық көрмейуін деп, бірін жықсыл қай жай, кіші біреуге жасқалын көргенге, сен болады екен. Қазақ баласының баласы үшін ембекін де арып, жырек таға ма? Олай болғанда, адам өз халақта тағыладың адамдығы жақғанымды білмей таға, қарым тоқ жасса махаббат - барыққы мағалусын да пайдасын жәре туре бір жар болуға жоса малдар  әзерілік болып, асылардың бері толған. Және еу оғанға берген денерекі тур-бірдің мұным өмерлік бәрі--а ихсай, әлеутерді, бұл қазағына бар бірмей-тұрсын, тарқыста ғаларын білмек, кімді бұр болыд киммет жоқ. Сон жасқан қарындардың қатқының иманып імен керек: ол - жүқ екені. Құдай тағала жаланыша жасап қала алмасың, азылаттың ғолымдын ешірсе, жоқыны калмай де, сондай білгенге қараның жерсе екен. Қазақ ның сеніз ұялған біліміз ғылымды кеметтік. Егерде біреуін да көңілің өзі де сапатынақ берсе, мұнша шарқалық, қайда басқа, біреудің кісі ісі десең де, осы көнем мақ жатып, сайда де сөздерікпен барана ж\n"
     ]
    }
   ],
   "source": [
    "print(sample(rnn, 1000, prime='М', top_k=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Қайтып ұялған дәнелік енсез болған, хайуан, малынан орынға қойықтанға жүр көзе жем, сезің тілелге, келеріп жоқ. Бір жүнек ісіп, қымнен таққасым. «Яныны , ағайынып жарылып, жарым жатырсыз болған мықтығын асарап, білеудің бірін қызып жүреді. Мұндай адам баласына пайдасы келе ұятады, кімге көрік болады. Мұндай ұят қылып тапатына жалапындып, еліншен жақсы қыламыз де бөлем ғана еліп тұрағанда. Адамның аламыз ғалалы қарамасыз де селгендігіңе біреуін бахыс көремек. Олар болмаса, ләлси адам басабар. Сар бағалсың женге мен соу кеп өзгенікпек көріп жүр. Бұлар - дән болған. Бұлардың мүлкінің ибарының жеткені жөм болса, ол ниетің ғылым болса, халақ бәрлән бұзатар фиғалақұран ақылды жақсы, жарымға жұрып жаратылға тұрғанның адам баласы ғана білгенімдікпенен тайсалмақ - өнірлік иелі «дарлыр, құдай тағаланың көңілге сипатына жерсез кісілерінің бәрі - пайдасан көрін, астыңның көрсе, қайты жақсы көріп, өзін ойлап қалары еді. Мандый өсіп, өзін өлсектерсің, кірсіз білеуге жаратып, жалған без келгенім өмер е\n"
     ]
    }
   ],
   "source": [
    "print(sample(rnn, 1000, prime='Қ', top_k=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ырса, сендігі есі менен қанып жергені қайтып алады. Ағайын қылып, біреуін тауып құрар атып, монын асыралып, түген де жақсы ерсі де, өзің адам баласы біресұғын тәрілгені керек болады. Женге жоқ рол соң, жарлысын жоқ болады, оның жұз қалайшаған махшар ісі емес, һәмманы да барады да шығада. Оның үшін адам баласы ғылым таққаным болмаса, малды сұрап сабыбық, бір тәрті мұрсат болса екен деп, үлгенің - моның игерін солдару кісіне қорықып, сұрасын дайдып келеді. Осы болады де алланың жары болған соң, жәнн ниңнің бетіндігіна нә сәрімлін ешеп тара баладын болса, жән- иіс болмаса, бірмененің қойы баласын деп жұр боларына орынсызын, бір иманы бар келікпен болып, оны күнме?- Я түйті, аның бәрі - жәрекі деген кісірер едіс көргенде жоздығытыны көрген кісіемен соңалы осы жүнде біріндер бір өзіненіңде өзің қызғанына қашжынып бола а ма? Біреуді қарқатқа қарсыт, аруызды табады, сайлауға жарамайды, азғыртық деп арыз дағылады. Ол маланда қаліңдер месіңде көппен көрсен, қулып-түгін, қымсат, ауылс- қуанын барқ\n"
     ]
    }
   ],
   "source": [
    "print(sample(rnn, 1000, prime='Ы', top_k=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Project 1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
